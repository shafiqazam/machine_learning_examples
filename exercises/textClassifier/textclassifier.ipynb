{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = ['edgar_allen_poe.txt', 'robert_frost.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "labels = []\n",
    "\n",
    "# Use enumerate to get the index of the files as well\n",
    "# First file -> index 0 and so on\n",
    "for label, f in enumerate(input_files):\n",
    "    for line in open(f, encoding='utf-8'):\n",
    "        # Remove new line by rstrip\n",
    "        line = line.rstrip().lower()\n",
    "        if line:\n",
    "            # Remove punctuation\n",
    "            line = line.translate(str.maketrans('','', string.punctuation))\n",
    "            input_texts.append(line)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text , test_text, Ytrain, Ytest = train_test_split(input_texts, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many train and test sets do we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1615, 539)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ytrain), len(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map word to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "# Unknown word -> Data not in train set but in test set\n",
    "word2idx = {\n",
    "    '<unk>' : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in train_text:\n",
    "    # Tokenize the line by splitting it into words\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        if token not in word2idx:\n",
    "            word2idx[token] = idx\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['as']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert word as string into integer as the mapping\n",
    "\n",
    "train_text_int = []\n",
    "test_text_int = []\n",
    "\n",
    "# Go through every line in the training set\n",
    "for text in train_text:\n",
    "    tokens = text.split()\n",
    "    line_as_int = [word2idx[token] for token in tokens]\n",
    "    train_text_int.append(line_as_int)\n",
    "\n",
    "for text in test_text:\n",
    "    tokens = text.split()\n",
    "    # If word not in training set, put 0 \n",
    "    line_as_int = [word2idx.get(token,0) for token in tokens]\n",
    "    test_text_int.append(line_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init A and Pi Matrices for both models\n",
    "# A => Transition matrix from V states -> V states\n",
    "# Pi => Prior Probability -> V states\n",
    "#  N markov models for n authors\n",
    "V = len(word2idx)\n",
    "\n",
    "# We use ones here as the one-hot smoothing\n",
    "A0 = np.ones((V,V))\n",
    "pi0 = np.ones(V)\n",
    "\n",
    "A1 = np.ones((V,V))\n",
    "pi1 = np.ones(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_counts(text_as_int, A, pi):\n",
    "    for tokens in text_as_int:\n",
    "        last_idx = None\n",
    "        for idx in tokens:\n",
    "            if last_idx is None:\n",
    "                # First word of the sentence -> Populate pi\n",
    "                pi[idx] += 1\n",
    "            else:\n",
    "                # the last word exists, so count a transition\n",
    "                A[last_idx, idx] += 1\n",
    "            # Set current word as last visited word\n",
    "            last_idx = idx\n",
    "\n",
    "# Zip method aggregrates to a tuple -> https://www.programiz.com/python-programming/methods/built-in/zip\n",
    "compute_counts([t for t,y in zip(train_text_int, Ytrain) if y == 0], A0, pi0)\n",
    "compute_counts([t for t,y in zip(train_text_int, Ytrain) if y == 1], A1, pi1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 /= A0.sum(axis=1, keepdims= True)\n",
    "pi0 /= pi0.sum()\n",
    "\n",
    "A1 /= A1.sum(axis=1, keepdims=True)\n",
    "pi1 /= pi1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log A and pi since we don't need the actual probs\n",
    "logA0 = np.log(A0)\n",
    "logpi0 = np.log(pi0)\n",
    "\n",
    "logA1 = np.log(A1)\n",
    "logpi1 = np.log(pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3430340557275542, 0.6569659442724458)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute priors\n",
    "# How many samples belong to set 0/1 in the training set\n",
    "count0 = sum(y == 0 for y in Ytrain)\n",
    "count1 = sum(y == 1 for y in Ytrain)\n",
    "total = len(Ytrain)\n",
    "# compute prior probability\n",
    "p0 = count0 / total\n",
    "p1 = count1 / total\n",
    "# need log probablity\n",
    "logp0 = np.log(p0)\n",
    "logp1 = np.log(p1)\n",
    "p0, p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the class distribution is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, logAs, logpis, logpriors):\n",
    "        self.logAs = logAs\n",
    "        self.logpis = logpis\n",
    "        self.logpriors = logpriors\n",
    "        self.K = len(logpriors)\n",
    "\n",
    "    # Compute how likely does a row belongs to a certain class (author)\n",
    "    def _compute_log_likelihood(self, input_, class_):\n",
    "        logA = self.logAs[class_]\n",
    "        logpi = self.logpis[class_]\n",
    "\n",
    "        last_idx = None\n",
    "        logprob = 0\n",
    "\n",
    "        for idx in input_:\n",
    "            if last_idx is None:\n",
    "                logprob += logpi[idx]\n",
    "            else:\n",
    "                logprob += logA[last_idx, idx]\n",
    "            last_idx = idx\n",
    "\n",
    "        return logprob\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        # arrays to store the predictions\n",
    "        predictions = np.zeros((len(inputs)))\n",
    "        for i, input_ in enumerate(inputs):\n",
    "            posteriors = [self._compute_log_likelihood(input_, c) + self.logpriors[c] for c in range(self.K)]\n",
    "            pred = np.argmax(posteriors)\n",
    "            predictions[i] = pred\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9962848297213622\n"
     ]
    }
   ],
   "source": [
    "# Classifier (Transition matrix, initial prob, prior prob)\n",
    "clf = Classifier([logA0, logA1], [logpi0, logpi1], [logp0, logp1])\n",
    "Ptrain = clf.predict(train_text_int)\n",
    "print(f\"Train acc: {np.mean(Ptrain == Ytrain)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8589981447124304\n"
     ]
    }
   ],
   "source": [
    "Ptest = clf.predict(test_text_int)\n",
    "print(f\"Test acc: {np.mean(Ptest == Ytest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has imbalanced count 33% - 66%\n",
    "\n",
    "Use a metric that takes it into account -> e.g Confusion Matrix, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 548,    6],\n",
       "       [   0, 1061]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Ytrain, Ptrain)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 96,  68],\n",
       "       [  8, 367]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test = confusion_matrix(Ytest, Ptest)\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9971804511278196"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Ytrain, Ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9061728395061728"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Ytest, Ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
